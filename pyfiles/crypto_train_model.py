"""
crypto_train_model.py

"""

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", message=".*is_sparse.*")
warnings.filterwarnings("ignore", message=".*backend2gui.*")

import os
import pathlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from dotenv import load_dotenv
import hopsworks
from hsml.schema import Schema
from hsml.model_schema import ModelSchema
from xgboost import XGBClassifier, plot_importance
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    confusion_matrix,
    classification_report,
)


def load_train_test_from_fv():
    load_dotenv()
    api_key = os.getenv("HOPSWORKS_API_KEY")
    project_name = os.getenv("HOPSWORKS_PROJECT", "ID2223_airquality")

    if api_key is None:
        raise ValueError("æ²¡æ‰¾åˆ° HOPSWORKS_API_KEYï¼Œè¯·åœ¨ .env é‡Œé…ç½®ä½ çš„ tokenã€‚")

    print("Logging into Hopsworks ...")
    project = hopsworks.login(api_key_value=api_key, project=project_name)
    fs = project.get_feature_store()

    # è¯»å– Feature View v1
    print("Getting Feature View 'crypto_featureview' v1 ...")
    fv = fs.get_feature_view(name="crypto_featureview", version=1)

    # ==================================================
    # ä¿®æ­£ç‚¹ï¼šä½¿ç”¨ training_data è·å– X å’Œ y
    # ==================================================
    print("Reading training data (X and y) from Feature View...")
    
    # training_data() ä¼šè¿”å› (Features, Labels) çš„å…ƒç»„
    # description éšä¾¿å†™ï¼Œä¸»è¦ä¸ºäº†è§¦å‘å®ƒç”Ÿæˆ/è¯»å–æ•°æ®
    X_fv, y_fv = fv.training_data(
        description="crypto_full_dataset"
    )

    # 1. æ‹¼æ¥ X å’Œ yï¼Œæ–¹ä¾¿ç»Ÿä¸€æŒ‰æ—¶é—´æ’åº
    df_all = pd.concat([X_fv, y_fv], axis=1)

    # 2. æŒ‰æ—¶é—´æ’åº (éå¸¸é‡è¦ï¼å¦åˆ™è¿˜æ˜¯ä¼šæ³„éœ²)
    print("Sorting by timestamp for manual time-series split...")
    df_all = df_all.sort_values("timestamp").reset_index(drop=True)

    # 3. æå–æ’åºåçš„ Label å’Œ Features
    y_all = df_all["label_up_24h"]
    X_all = df_all.drop(columns=["label_up_24h"])

    # 4. æ‰‹åŠ¨æŒ‰æ—¶é—´åˆ‡åˆ† (å‰ 80% è®­ç»ƒï¼Œå 20% æµ‹è¯•)
    split_index = int(len(df_all) * 0.8)

    X_train = X_all.iloc[:split_index]
    y_train = y_all.iloc[:split_index]

    X_test = X_all.iloc[split_index:]
    y_test = y_all.iloc[split_index:]

    print(f"Time-series split complete.")
    print(f"Train: {X_train.timestamp.min()} -> {X_train.timestamp.max()} (Size: {len(X_train)})")
    print(f"Test : {X_test.timestamp.min()} -> {X_test.timestamp.max()} (Size: {len(X_test)})")

    # 5. æœ€åå»æ‰ timestamp åˆ— (XGBoost ä¸éœ€è¦å®ƒï¼Œä¸”é˜²æ­¢ä½œä¸ºå”¯ä¸€IDè¢«è¿‡æ‹Ÿåˆ)
    X_train = X_train.drop(columns=["timestamp"])
    X_test = X_test.drop(columns=["timestamp"])

    return project, X_train, X_test, y_train, y_test

# ----------------------------------------------------------------------
# 2. è®­ç»ƒ XGBoost æ¨¡å‹
# ----------------------------------------------------------------------

def train_xgb_classifier(X_train, y_train, X_test, y_test):
    """
    è®­ç»ƒä¸€ä¸ª XGBoost äºŒåˆ†ç±»æ¨¡å‹ï¼Œè¿”å›è®­ç»ƒå¥½çš„æ¨¡å‹å’Œä¸€äº›æŒ‡æ ‡ã€‚
    """
    
    if isinstance(y_train, pd.DataFrame):
        y_train = y_train.iloc[:, 0]
    if isinstance(y_test, pd.DataFrame):
        y_test = y_test.iloc[:, 0]

    print("Training XGBoost classifier ...")
    model = XGBClassifier(
        n_estimators=300,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        objective="binary:logistic",
        eval_metric="logloss",
        n_jobs=-1,
        tree_method="hist",  # æ›´å¿«
    )
    
    def _sanitize_X_for_xgb(X: pd.DataFrame) -> pd.DataFrame:
        X = X.copy()
    
        # 1) æœ€æ¨èï¼šç›´æ¥æ‰”æ‰ timestampï¼ˆä½ å·²ç»æœ‰ hour_of_day/day_of_week/is_weekendï¼‰
        if "timestamp" in X.columns:
            X = X.drop(columns=["timestamp"])
    
        # 2) å¦‚æœè¿˜æœ‰ object åˆ—ï¼Œæœ€å¥½ä¹Ÿå¤„ç†æ‰ï¼ˆé¿å…ä¸‹æ¬¡å†è¸©é›·ï¼‰
        obj_cols = X.select_dtypes(include=["object"]).columns.tolist()
        if obj_cols:
            print("Dropping non-numeric object columns:", obj_cols)
            X = X.drop(columns=obj_cols)

        return X


    X_train = _sanitize_X_for_xgb(X_train)
    X_test  = _sanitize_X_for_xgb(X_test)
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_train, y_train), (X_test, y_test)],
        verbose=False,
    )


    # é¢„æµ‹
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    try:
        roc = roc_auc_score(y_test, y_proba)
    except ValueError:
        roc = float("nan")  # ä¸‡ä¸€æŸä¸€ç±»å…¨è¢«é¢„æµ‹æˆåŒä¸€ç±»ï¼ŒAUC å¯èƒ½æŠ¥é”™

    print(f"Accuracy: {acc:.4f}, ROC AUC: {roc:.4f}")
    print("\nClassification report:")
    print(classification_report(y_test, y_pred))

    return model, y_pred, y_proba, acc, roc


# ----------------------------------------------------------------------
# 3. å¯è§†åŒ–ï¼šé¢„æµ‹ vs çœŸå® & feature importance & æ··æ·†çŸ©é˜µ
# ----------------------------------------------------------------------


def ensure_dirs():
    """
    åˆ›å»º images/ å’Œ models/ ç›®å½•
    """
    base_dir = pathlib.Path(".")
    images_dir = base_dir / "images_crypto"
    model_dir = base_dir / "crypto_model"

    images_dir.mkdir(exist_ok=True, parents=True)
    model_dir.mkdir(exist_ok=True, parents=True)

    return images_dir, model_dir


def plot_predictions(y_test, y_proba, images_dir: pathlib.Path):
    """
    ç±»ä¼¼è€å¸ˆ PM2.5 çš„æ—¶é—´åºåˆ—å›¾ï¼Œè¿™é‡Œç”» test é›†çš„é¢„æµ‹æ¦‚ç‡ vs çœŸå®æ ‡ç­¾ã€‚
    x è½´ç”¨æ ·æœ¬ indexã€‚
    """
    print("Plotting predictions ...")
    idx = np.arange(len(y_test))

    plt.figure(figsize=(10, 5))
    plt.plot(idx, y_test.values, label="Actual label (0/1)", linewidth=1)
    plt.plot(idx, y_proba, label="Predicted probability (up)", linewidth=1)
    plt.xlabel("Test sample index")
    plt.ylabel("Label / Probability")
    plt.title("BTC 1h Up Movement - Actual vs Predicted Probability")
    plt.legend()
    plt.tight_layout()

    path = images_dir / "pred_vs_actual.png"
    plt.savefig(path)
    plt.close()
    print(f"Saved prediction plot to {path}")


def plot_confusion(y_test, y_pred, images_dir: pathlib.Path):
    """
    ç”»æ··æ·†çŸ©é˜µã€‚
    """
    print("Plotting confusion matrix ...")
    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(4, 4))
    sns.heatmap(
        cm,
        annot=True,
        fmt="d",
        cmap="Blues",
        cbar=False,
        xticklabels=["Down / 0", "Up / 1"],
        yticklabels=["Down / 0", "Up / 1"],
    )
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix - BTC 1h Up/Down")
    plt.tight_layout()

    path = images_dir / "confusion_matrix.png"
    plt.savefig(path)
    plt.close()
    print(f"Saved confusion matrix to {path}")


def plot_feature_importance(model, images_dir: pathlib.Path):
    """
    åˆ©ç”¨ xgboost.plot_importance ç”»ç‰¹å¾é‡è¦æ€§ã€‚
    """
    print("Plotting feature importance ...")
    plt.figure(figsize=(8, 6))
    plot_importance(model, max_num_features=20, importance_type="gain")
    plt.tight_layout()

    path = images_dir / "feature_importance.png"
    plt.savefig(path)
    plt.close()
    print(f"Saved feature importance plot to {path}")


# ----------------------------------------------------------------------
# 4. ä¿å­˜æ¨¡å‹ & æ³¨å†Œåˆ° Model Registry
# ----------------------------------------------------------------------


def save_and_register_model(project,
                            model,
                            X_train,
                            y_train,
                            model_dir: pathlib.Path,
                            acc: float,
                            roc: float):
    """
    - æŠŠ XGBoost æ¨¡å‹ä¿å­˜åˆ° model_dir/model.json
    - ä½¿ç”¨ Hopsworks Model Registry æ³¨å†Œä¸€ä¸ª Python Model
    """

    print("Saving model to local directory ...")
    model_path = model_dir / "model.json"
    model.save_model(str(model_path))
    print(f"XGBoost model saved to {model_path}")

    metrics = {
        "accuracy": str(acc),
        "roc_auc": str(roc),
    }

    print("Creating model schema ...")
    
    input_schema = Schema(X_train)

    # y_train å¯èƒ½æ˜¯ Series æˆ– 1åˆ— DataFrameï¼Œç»Ÿä¸€æˆ 1åˆ— DataFrame
    if isinstance(y_train, pd.Series):
        y_schema_df = y_train.to_frame(name="label_up_24h")
    else:
        # DataFrameï¼šç¡®ä¿åªæœ‰ä¸€åˆ—ï¼Œå¹¶å‘½åä¸º label_up_6h
        y_schema_df = y_train.copy()
        if y_schema_df.shape[1] != 1:
            raise ValueError(f"Expected y_train to have 1 column, got {y_schema_df.shape[1]}")
        y_schema_df.columns = ["label_up_24h"]
    
    output_schema = Schema(y_schema_df)

    # input_schema = Schema(X_train)
    # output_schema = Schema(y_train.to_frame(name="label_up_6h"))
    model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)

    print(" Registering model in Hopsworks Model Registry ...")
    mr = project.get_model_registry()

    crypto_model = mr.python.create_model(
        name="crypto_xgboost_direction_model",
        description="XGBoost classifier predicting Bitcoin 1h up/down movement from engineered CoinGecko features.",
        metrics=metrics,
        model_schema=model_schema,
        input_example=X_train.iloc[:1],
    )

    # æŠŠæ•´ä¸ª model_dir ä¸Šä¼ åˆ° MR
    crypto_model.save(str(model_dir))
    print("Model registered in Hopsworks Model Registry.")


# ----------------------------------------------------------------------
# main
# ----------------------------------------------------------------------


    
def main():
    # 1) ä» Feature View æ‹¿åˆ° train / test (å·²æŒ‰æ—¶é—´åˆ‡åˆ†)
    project, X_train, X_test, y_train, y_test = load_train_test_from_fv()

    # 2) è®­ç»ƒæ¨¡å‹
    model, y_pred, y_proba, acc, roc = train_xgb_classifier(X_train, y_train, X_test, y_test)

    # 3) ç”»å›¾ (é¢„æµ‹ç»“æœ & æ··æ·†çŸ©é˜µ)
    images_dir, model_dir = ensure_dirs()
    plot_predictions(y_test, y_proba, images_dir)
    plot_confusion(y_test, y_pred, images_dir)
    plot_feature_importance(model, images_dir)

    # 4) ä¿å­˜ & æ³¨å†Œæ¨¡å‹
    save_and_register_model(project, model, X_train, y_train, model_dir, acc, roc)

    print("\nTraining pipeline finished. Starting Debugging Analysis...")

    # ==========================================
    # ğŸ•µï¸â€â™‚ï¸ DEBUG: å¯»æ‰¾æ³„éœ²ç‰¹å¾ (Safe Mode)
    # ==========================================
    
    # --- A. ç‰¹å¾é‡è¦æ€§åˆ†æ ---
    importance = model.feature_importances_
    # ç¡®ä¿åˆ—åæ˜¯åˆ—è¡¨
    feature_names = X_train.columns.tolist()
    
    feat_imp = pd.DataFrame({
        'feature': feature_names,
        'importance': importance
    }).sort_values('importance', ascending=False)
    
    print("Top 10 Most Important Features (If one is > 0.5, that's your leak):")
    print(feat_imp.head(10))
    
    # ç”»ç‰¹å¾é‡è¦æ€§å›¾
    try:
        plt.figure(figsize=(10, 6))
        sns.barplot(x='importance', y='feature', data=feat_imp.head(10))
        plt.title("Feature Importance (The Leak Detector)")
        plt.tight_layout()
        plt.show()
    except Exception as e:
        print(f"Could not plot feature importance interactively: {e}")

    # --- B. ç›¸å…³æ€§åˆ†æ (Safe Mode) ---
    print("\nChecking Correlation with Label...")
    
    # 1. å¤åˆ¶ X_train å¹¶åªä¿ç•™æ•°å€¼åˆ— (é˜²æ­¢å­—ç¬¦ä¸²æŠ¥é”™)
    debug_df = X_train.select_dtypes(include=[np.number]).copy()
    
    # 2. å®‰å…¨åˆå¹¶ label (ä½¿ç”¨ values é¿å…ç´¢å¼•ä¸ä¸€è‡´é—®é¢˜)
    # y_train å¯èƒ½æ˜¯ DataFrame ä¹Ÿå¯èƒ½æ˜¯ Seriesï¼Œç»Ÿä¸€è½¬æˆ numpy array
    if isinstance(y_train, pd.DataFrame):
        target_vals = y_train.iloc[:, 0].values
    else:
        target_vals = y_train.values
        
    debug_df["LABEL_TARGET"] = target_vals
    
    # 3. è®¡ç®—ç›¸å…³æ€§
    corr = debug_df.corr()["LABEL_TARGET"].sort_values(ascending=False)
    
    # 4. æ‰“å°ç»“æœ (æ’é™¤ LABEL_TARGET è‡ªå·±)
    corr = corr.drop("LABEL_TARGET", errors="ignore")
    
    print("\nTop Positive Correlations (Closer to 1.0 = Leak):")
    print(corr.head(5))
    
    print("\nTop Negative Correlations (Closer to -1.0 = Leak):")
    print(corr.tail(5))


if __name__ == "__main__":
    main()
